{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5565160c-4ff8-474f-a854-53defd2b76c5",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca3833c-4a18-4075-a401-1ef3ed005f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-25 15:33:03--  https://certification-data.obs.cn-north-4.myhuaweicloud.com/ENG/HCIP-AI%20EI%20Developer/V2.5/chapter4/NMT-Transformer-Pytorch.zip\n",
      "Resolving proxy.modelarts.com (proxy.modelarts.com)... 192.168.0.180\n",
      "Connecting to proxy.modelarts.com (proxy.modelarts.com)|192.168.0.180|:80... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 374496134 (357M) [application/zip]\n",
      "Saving to: ‘NMT-Transformer-Pytorch.zip’\n",
      "\n",
      "NMT-Transformer-Pyt 100%[===================>] 357.15M  36.5MB/s    in 10s     \n",
      "\n",
      "2026-02-25 15:33:13 (34.8 MB/s) - ‘NMT-Transformer-Pytorch.zip’ saved [374496134/374496134]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://certification-data.obs.cn-north-4.myhuaweicloud.com/ENG/HCIP-AI%20EI%20Developer/V2.5/chapter4/NMT-Transformer-Pytorch.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e34026-0a25-4b10-9252-5d09b5a2f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  NMT-Transformer-Pytorch.zip\n",
      "   creating: NMT-Transformer-Pytorch/\n",
      "  inflating: NMT-Transformer-Pytorch/.DS_Store  \n",
      "   creating: NMT-Transformer-Pytorch/.ipynb_checkpoints/\n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/beam_decoder-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/config-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/creatJson-checkpoint.ipynb  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/data_loader-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/model-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/NMT-Pytorch-checkpoint.ipynb  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/train-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/.ipynb_checkpoints/utils-checkpoint.py  \n",
      "  inflating: NMT-Transformer-Pytorch/beam_decoder.py  \n",
      "  inflating: NMT-Transformer-Pytorch/config.py  \n",
      "   creating: NMT-Transformer-Pytorch/data/\n",
      "  inflating: NMT-Transformer-Pytorch/data/.DS_Store  \n",
      "   creating: NMT-Transformer-Pytorch/data/.ipynb_checkpoints/\n",
      "  inflating: NMT-Transformer-Pytorch/data/corpus.en  \n",
      "  inflating: NMT-Transformer-Pytorch/data/corpus.fr  \n",
      "   creating: NMT-Transformer-Pytorch/data/json/\n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.DS_Store  \n",
      "   creating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/\n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/dev-checkpoint.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/dev_fr-checkpoint.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/test-checkpoint.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/train-checkpoint.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/.ipynb_checkpoints/train_fr-checkpoint.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/dev.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/test.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data/json/train.json  \n",
      "  inflating: NMT-Transformer-Pytorch/data_loader.py  \n",
      "   creating: NMT-Transformer-Pytorch/experiment/\n",
      "  inflating: NMT-Transformer-Pytorch/model.py  \n",
      "  inflating: NMT-Transformer-Pytorch/NMT-Pytorch.ipynb  \n",
      "   creating: NMT-Transformer-Pytorch/pretrain/\n",
      "  inflating: NMT-Transformer-Pytorch/pretrain/model.pth  \n",
      "  inflating: NMT-Transformer-Pytorch/requirements.txt  \n",
      "   creating: NMT-Transformer-Pytorch/tokenizer/\n",
      "   creating: NMT-Transformer-Pytorch/tokenizer/.ipynb_checkpoints/\n",
      "  inflating: NMT-Transformer-Pytorch/tokenizer/eng.model  \n",
      "  inflating: NMT-Transformer-Pytorch/tokenizer/eng.vocab  \n",
      "  inflating: NMT-Transformer-Pytorch/tokenizer/fra.model  \n",
      "  inflating: NMT-Transformer-Pytorch/tokenizer/fra.vocab  \n",
      "  inflating: NMT-Transformer-Pytorch/train.py  \n",
      "  inflating: NMT-Transformer-Pytorch/utils.py  \n",
      "   creating: NMT-Transformer-Pytorch/__pycache__/\n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/beam_decoder.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/beam_decoder.cpython-37.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/config.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/config.cpython-36.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/config.cpython-37.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/data_loader.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/data_loader.cpython-36.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/data_loader.cpython-37.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/model.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/model.cpython-36.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/model.cpython-37.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/train.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/train.cpython-36.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/train.cpython-37.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/utils.cpython-311.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/utils.cpython-36.pyc  \n",
      "  inflating: NMT-Transformer-Pytorch/__pycache__/utils.cpython-37.pyc  \n"
     ]
    }
   ],
   "source": [
    "!unzip NMT-Transformer-Pytorch.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a67e346-bec3-4fdd-95d8-b6292e9ff06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple/\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from -r Transformer-Pytorch/requirements.txt (line 1)) (1.19.5)\n",
      "Collecting sacrebleu==1.4.14\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/sacrebleu/1.4.14/sacrebleu-1.4.14-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from -r Transformer-Pytorch/requirements.txt (line 3)) (0.22.1)\n",
      "Collecting sentencepiece==0.1.94\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/sentencepiece/0.1.94/sentencepiece-0.1.94-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from -r Transformer-Pytorch/requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: torchvision in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from -r Transformer-Pytorch/requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from -r Transformer-Pytorch/requirements.txt (line 7)) (4.64.1)\n",
      "Collecting portalocker\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/portalocker/2.7.0/portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from scikit-learn->-r Transformer-Pytorch/requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from scikit-learn->-r Transformer-Pytorch/requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from torch->-r Transformer-Pytorch/requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from torchvision->-r Transformer-Pytorch/requirements.txt (line 6)) (9.2.0)\n",
      "Installing collected packages: sentencepiece, portalocker, sacrebleu\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.97\n",
      "    Uninstalling sentencepiece-0.1.97:\n",
      "      Successfully uninstalled sentencepiece-0.1.97\n",
      "Successfully installed portalocker-2.7.0 sacrebleu-1.4.14 sentencepiece-0.1.94\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r Transformer-Pytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b361c0-33f6-44e0-9835-729dbc269495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhhhh\n"
     ]
    }
   ],
   "source": [
    "print(\"hhhhh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6582656e-8291-46a7-a61c-82ab7a875d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Transformer-Pytorch'\n",
      "/home/ma-user/work/Transformer-Pytorch\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'english_tokenizer_load' from 'utils' (/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17272/432332430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Transformer-Pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMTDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_label\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mLabelSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiGPULossCompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/Transformer-Pytorch/data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menglish_tokenizer_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrance_tokenizer_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'english_tokenizer_load' from 'utils' (/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "#!pip install data_loader\n",
    "import utils\n",
    "import config\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#%cd Transformer-Pytorch\n",
    "from data_loader import MTDataset\n",
    "from model import make_label , LabelSmoothing\n",
    "from train import MultiGPULossCompute\n",
    "from utils import france_tokenizer_load\n",
    "from beam_decoder import beam_search\n",
    "from model import batch_greedy_decode\n",
    "import sacrebleu\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a85000-5e39-46d4-b7a6-bfee885934b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
