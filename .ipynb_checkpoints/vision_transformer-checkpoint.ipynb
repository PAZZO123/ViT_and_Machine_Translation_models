{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c399566-4f1e-464c-88ca-bf2e0e8d1f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple/\n",
      "Collecting download\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/download/0.3.5/download-0.3.5-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from download) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from download) (4.64.1)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->download) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->download) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->download) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->download) (2022.9.14)\n",
      "Installing collected packages: download\n",
      "Successfully installed download-0.3.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f09b948-93db-4f97-8fcc-192a06244d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-25 20:53:47--  https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip\n",
      "Resolving proxy.modelarts.com (proxy.modelarts.com)... 192.168.0.180\n",
      "Connecting to proxy.modelarts.com (proxy.modelarts.com)|192.168.0.180|:80... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 512895647 (489M) [application/zip]\n",
      "Saving to: ‘vit_imagenet_dataset.zip’\n",
      "\n",
      "vit_imagenet_datase 100%[===================>] 489.13M  33.5MB/s    in 16s     \n",
      "\n",
      "2026-02-25 20:54:03 (30.8 MB/s) - ‘vit_imagenet_dataset.zip’ saved [512895647/512895647]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "#!wget -c https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/vit_imagenet_dataset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02eacb-2d6f-4b9e-b579-21c1a0d3689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip vit_imagenet_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe87b8c-c6ed-4529-aa0f-d326334d944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple/\n",
      "Collecting mindspore\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/mindspore/2.0.0/mindspore-2.0.0-cp37-cp37m-manylinux1_x86_64.whl (947.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.2/947.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from mindspore) (1.19.5)\n",
      "Collecting asttokens>=2.0.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/asttokens/2.4.1/asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from mindspore) (5.8.0)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from mindspore) (3.20.1)\n",
      "Collecting scipy>=1.5.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/scipy/1.7.3/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from mindspore) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from mindspore) (21.3)\n",
      "Collecting astunparse>=1.6.3\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/astunparse/1.6.3/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from asttokens>=2.0.4->mindspore) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from astunparse>=1.6.3->mindspore) (0.37.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from packaging>=20.0->mindspore) (3.0.9)\n",
      "Installing collected packages: scipy, astunparse, asttokens, mindspore\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "Successfully installed asttokens-2.4.1 astunparse-1.6.3 mindspore-2.0.0 scipy-1.7.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cb4ae2-f321-4864-a725-21e66c517e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "from mindspore.dataset import ImageFolderDataset\n",
    "import mindspore.dataset.vision as transforms\n",
    "\n",
    "data_path='./dataset/'\n",
    "mean=[0.485*255, 0.456*255, 0.406*255]\n",
    "std=[0.299*255, 0.244*255, 0.225*255]\n",
    "\n",
    "dataset_train=ImageFolderDataset(os.path.join(data_path, 'train'), shuffle=True)\n",
    "trans_train=[\n",
    "    transforms.RandomCropDecodeResize(size=224, scale=(0.08, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(prob=0.5),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    transform.HWC2CHW()\n",
    "    \n",
    "]\n",
    "dataset_train=dataset_train.map(operations=trans_train, input_columns=[\"image\"])\n",
    "dataset_train=dataset_train.batch(batch_size=16, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485714b-afd7-48a9-bc52-ed4749c6a098",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc12ccb3-a5df-4315-b912-962cbb88dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn, ops\n",
    "\n",
    "\n",
    "class Attention(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 num_heads: int = 8,\n",
    "                 keep_prob: float = 1.0,\n",
    "                 attention_keep_prob: float = 1.0):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = ms.Tensor(head_dim ** -0.5)\n",
    "\n",
    "        self.qkv = nn.Dense(dim, dim * 3)\n",
    "        self.attn_drop = nn.Dropout(p=1.0-attention_keep_prob)\n",
    "        self.out = nn.Dense(dim, dim)\n",
    "        self.out_drop = nn.Dropout(p=1.0-keep_prob)\n",
    "        self.attn_matmul_v = ops.BatchMatMul()\n",
    "        self.q_matmul_k = ops.BatchMatMul(transpose_b=True)\n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Attention construct.\"\"\"\n",
    "        b, n, c = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        qkv = ops.reshape(qkv, (b, n, 3, self.num_heads, c // self.num_heads))\n",
    "        qkv = ops.transpose(qkv, (2, 0, 3, 1, 4))\n",
    "        q, k, v = ops.unstack(qkv, axis=0)\n",
    "        attn = self.q_matmul_k(q, k)\n",
    "        attn = ops.mul(attn, self.scale)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        out = self.attn_matmul_v(attn, v)\n",
    "        out = ops.transpose(out, (0, 2, 1, 3))\n",
    "        out = ops.reshape(out, (b, n, c))\n",
    "        out = self.out(out)\n",
    "        out = self.out_drop(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bed71-541e-4bd7-bafd-2ef2dde3ac2e",
   "metadata": {},
   "source": [
    "### Transform Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54208aa2-4811-483e-a281-30bc2438a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "class FeedForward(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 hidden_features: Optional[int] = None,\n",
    "                 out_features: Optional[int] = None,\n",
    "                 activation: nn.Cell = nn.GELU,\n",
    "                 keep_prob: float = 1.0):\n",
    "        super(FeedForward, self).__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.dense1 = nn.Dense(in_features, hidden_features)\n",
    "        self.activation = activation()\n",
    "        self.dense2 = nn.Dense(hidden_features, out_features)\n",
    "        self.dropout = nn.Dropout(p=1.0-keep_prob)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Feed Forward construct.\"\"\"\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualCell(nn.Cell):\n",
    "    def __init__(self, cell):\n",
    "        super(ResidualCell, self).__init__()\n",
    "        self.cell = cell\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualCell construct.\"\"\"\n",
    "        return self.cell(x) + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430822ed-b032-4517-a832-072d47678d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 dim:int,\n",
    "                 num_layers:int,\n",
    "                 num_heads:int,\n",
    "                 mlp_dim:int,\n",
    "                 keep_prob:float=1.0,\n",
    "                 attention_keep_prob:float=1.0,\n",
    "                 drop_path_keep_prob:float=1.0,\n",
    "                 activation:nn.GELU,\n",
    "                 norm:nn.Cell=nn.LayerNom):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        layers=[]\n",
    "        for _ in range(num_layers):\n",
    "            normalization1=norm((dim,))\n",
    "            normalization2=norm((dim,))\n",
    "            attention=Attention(dim=dim,\n",
    "                                num_heads=num_heads,\n",
    "                                keep_prob=keep_prob,\n",
    "                                attention_keep_prob=attention_keep_prob)\n",
    "            \n",
    "            feedforward=FeedForward(in_features=dim,\n",
    "                                    hidden_features=mlp_dim,\n",
    "                                    activation=activation,\n",
    "                                    keep_prob=keep_prob)\n",
    "            \n",
    "            layers.append(\n",
    "            nn.SequentialCell([\n",
    "                ResidualCell(nn.SequentialCell([normalization1,attention])),\n",
    "                ResidualCell(nn.SequentialCell([normalization2,feedforward]))\n",
    "                \n",
    "            ])\n",
    "            )\n",
    "        self.layers=nn.SequentialCell(layers)\n",
    "    def construct(self, x):\n",
    "        return self.layers(x)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
